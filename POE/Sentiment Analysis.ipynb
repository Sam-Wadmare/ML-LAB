{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1327d2f2-24d4-48c9-b405-419a1c5e5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195b28c7-169c-451c-ab08-931a5b33b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>732</td>\n",
       "      <td>Collaborating on a science project that receiv...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2017-08-18 18:20:00</td>\n",
       "      <td>ScienceProjectSuccessHighSchool</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#ScienceFairWinner #HighSchoolScience</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>733</td>\n",
       "      <td>Attending a surprise birthday party organized ...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2018-06-22 14:15:00</td>\n",
       "      <td>BirthdayPartyJoyHighSchool</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#SurpriseCelebration #HighSchoolFriendship</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>734</td>\n",
       "      <td>Successfully fundraising for a school charity ...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2019-04-05 17:30:00</td>\n",
       "      <td>CharityFundraisingTriumphHighSchool</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#CommunityGiving #HighSchoolPhilanthropy</td>\n",
       "      <td>22.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>735</td>\n",
       "      <td>Participating in a multicultural festival, cel...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2020-02-29 20:45:00</td>\n",
       "      <td>MulticulturalFestivalJoyHighSchool</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#CulturalCelebration #HighSchoolUnity</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>732</td>\n",
       "      <td>736</td>\n",
       "      <td>Organizing a virtual talent show during challe...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2020-11-15 15:15:00</td>\n",
       "      <td>VirtualTalentShowSuccessHighSchool</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#VirtualEntertainment #HighSchoolPositivity</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0  \\\n",
       "0               0           0   \n",
       "1               1           1   \n",
       "2               2           2   \n",
       "3               3           3   \n",
       "4               4           4   \n",
       "..            ...         ...   \n",
       "727           728         732   \n",
       "728           729         733   \n",
       "729           730         734   \n",
       "730           731         735   \n",
       "731           732         736   \n",
       "\n",
       "                                                  Text    Sentiment  \\\n",
       "0     Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1     Traffic was terrible this morning.           ...   Negative     \n",
       "2     Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
       "3     Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4     Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "..                                                 ...          ...   \n",
       "727  Collaborating on a science project that receiv...       Happy    \n",
       "728  Attending a surprise birthday party organized ...       Happy    \n",
       "729  Successfully fundraising for a school charity ...       Happy    \n",
       "730  Participating in a multicultural festival, cel...       Happy    \n",
       "731  Organizing a virtual talent show during challe...       Happy    \n",
       "\n",
       "               Timestamp                                   User     Platform  \\\n",
       "0    2023-01-15 12:30:00                          User123          Twitter     \n",
       "1    2023-01-15 08:45:00                          CommuterX        Twitter     \n",
       "2    2023-01-15 15:45:00                          FitnessFan      Instagram    \n",
       "3    2023-01-15 18:20:00                          AdventureX       Facebook    \n",
       "4    2023-01-15 19:55:00                          ChefCook        Instagram    \n",
       "..                   ...                                    ...          ...   \n",
       "727  2017-08-18 18:20:00       ScienceProjectSuccessHighSchool     Facebook    \n",
       "728  2018-06-22 14:15:00            BirthdayPartyJoyHighSchool    Instagram    \n",
       "729  2019-04-05 17:30:00   CharityFundraisingTriumphHighSchool      Twitter    \n",
       "730  2020-02-29 20:45:00    MulticulturalFestivalJoyHighSchool     Facebook    \n",
       "731  2020-11-15 15:15:00    VirtualTalentShowSuccessHighSchool    Instagram    \n",
       "\n",
       "                                          Hashtags  Retweets  Likes  \\\n",
       "0        #Nature #Park                                  15.0   30.0   \n",
       "1        #Traffic #Morning                               5.0   10.0   \n",
       "2        #Fitness #Workout                              20.0   40.0   \n",
       "3        #Travel #Adventure                              8.0   15.0   \n",
       "4        #Cooking #Food                                 12.0   25.0   \n",
       "..                                             ...       ...    ...   \n",
       "727         #ScienceFairWinner #HighSchoolScience       20.0   39.0   \n",
       "728    #SurpriseCelebration #HighSchoolFriendship       25.0   48.0   \n",
       "729      #CommunityGiving #HighSchoolPhilanthropy       22.0   42.0   \n",
       "730         #CulturalCelebration #HighSchoolUnity       21.0   43.0   \n",
       "731   #VirtualEntertainment #HighSchoolPositivity       24.0   47.0   \n",
       "\n",
       "          Country  Year  Month  Day  Hour  \n",
       "0       USA        2023      1   15    12  \n",
       "1       Canada     2023      1   15     8  \n",
       "2     USA          2023      1   15    15  \n",
       "3       UK         2023      1   15    18  \n",
       "4      Australia   2023      1   15    19  \n",
       "..            ...   ...    ...  ...   ...  \n",
       "727            UK  2017      8   18    18  \n",
       "728           USA  2018      6   22    14  \n",
       "729        Canada  2019      4    5    17  \n",
       "730            UK  2020      2   29    20  \n",
       "731           USA  2020     11   15    15  \n",
       "\n",
       "[732 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d9ccb9-1060-4421-b585-ef630b594523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing required packages\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ff6b8c-b520-402f-8ac2-fda1ff0c1da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\athar\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\athar\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\athar\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\athar\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\athar\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\athar\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\athar\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f59fc6e-6571-49a7-9b9a-f15eae41aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased data:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     enjoying a beautiful day at the park!        ...\n",
       "1     traffic was terrible this morning.           ...\n",
       "2     just finished an amazing workout! ðŸ’ª          ...\n",
       "3     excited about the upcoming weekend getaway!  ...\n",
       "4     trying out a new recipe for dinner tonight.  ...\n",
       "Name: lower_text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from textblob import TextBlob\n",
    "# lowercasing\n",
    "df[\"lower_text\"] = df[\"Text\"].str.lower()\n",
    "print(\"Lowercased data:\\n\")\n",
    "df[\"lower_text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f0a868-5442-4273-97e1-ff9cb3815c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuations removed:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     enjoying a beautiful day at the park         ...\n",
       "1     traffic was terrible this morning            ...\n",
       "2     just finished an amazing workout ðŸ’ª           ...\n",
       "3     excited about the upcoming weekend getaway   ...\n",
       "4     trying out a new recipe for dinner tonight   ...\n",
       "Name: no_punct, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation\n",
    "df[\"no_punct\"] = df[\"lower_text\"].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)))\n",
    "print(\"Punctuations removed:\\n\")\n",
    "df[\"no_punct\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "449fc91b-d2a1-4585-b4ab-a6170193cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokenisation:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         [enjoying, a, beautiful, day, at, the, park]\n",
       "1              [traffic, was, terrible, this, morning]\n",
       "2            [just, finished, an, amazing, workout, ðŸ’ª]\n",
       "3    [excited, about, the, upcoming, weekend, getaway]\n",
       "4    [trying, out, a, new, recipe, for, dinner, ton...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "df[\"tokens\"] = df[\"no_punct\"].apply(lambda x: x.split())\n",
    "print(\"Word tokenisation:\\n\")\n",
    "df[\"tokens\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "180fd4a8-f557-4516-9bf0-3b9e2b59e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords Removed:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                [enjoying, beautiful, day, park]\n",
       "1                    [traffic, terrible, morning]\n",
       "2           [just, finished, amazing, workout, ðŸ’ª]\n",
       "3    [excited, about, upcoming, weekend, getaway]\n",
       "4     [trying, out, new, recipe, dinner, tonight]\n",
       "Name: no_stopwords, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set([\n",
    "    \"the\", \"and\", \"is\", \"in\", \"to\", \"of\", \"a\", \"on\", \"for\", \"with\", \"at\", \"by\",\n",
    "    \"an\", \"be\", \"this\", \"that\", \"it\", \"from\", \"as\", \"are\", \"was\", \"were\"\n",
    "])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#remove stopwords\n",
    "df[\"no_stopwords\"] = df[\"tokens\"].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "print(\"Stopwords Removed:\\n\")\n",
    "df[\"no_stopwords\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7672d8f-cc0f-4a8f-afe9-cfdefe964653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                 [enjoy, beauti, day, park]\n",
       "1                   [traffic, terribl, morn]\n",
       "2           [just, finish, amaz, workout, ðŸ’ª]\n",
       "3    [excit, about, upcom, weekend, getaway]\n",
       "4    [tri, out, new, recip, dinner, tonight]\n",
       "Name: stemmed_tokens, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Stemming\n",
    "df[\"stemmed_tokens\"] = df[\"no_stopwords\"].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "print(\"Stemmed Tokens:\\n\")\n",
    "df[\"stemmed_tokens\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16ae144c-c9ba-477b-8495-f81ecf47de07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newly added Columns:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower_text</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>enjoying a beautiful day at the park         ...</td>\n",
       "      <td>[enjoying, a, beautiful, day, at, the, park]</td>\n",
       "      <td>[enjoying, beautiful, day, park]</td>\n",
       "      <td>[enjoy, beauti, day, park]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic was terrible this morning.           ...</td>\n",
       "      <td>traffic was terrible this morning            ...</td>\n",
       "      <td>[traffic, was, terrible, this, morning]</td>\n",
       "      <td>[traffic, terrible, morning]</td>\n",
       "      <td>[traffic, terribl, morn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just finished an amazing workout! ðŸ’ª          ...</td>\n",
       "      <td>just finished an amazing workout ðŸ’ª           ...</td>\n",
       "      <td>[just, finished, an, amazing, workout, ðŸ’ª]</td>\n",
       "      <td>[just, finished, amazing, workout, ðŸ’ª]</td>\n",
       "      <td>[just, finish, amaz, workout, ðŸ’ª]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>excited about the upcoming weekend getaway   ...</td>\n",
       "      <td>[excited, about, the, upcoming, weekend, getaway]</td>\n",
       "      <td>[excited, about, upcoming, weekend, getaway]</td>\n",
       "      <td>[excit, about, upcom, weekend, getaway]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>trying out a new recipe for dinner tonight   ...</td>\n",
       "      <td>[trying, out, a, new, recipe, for, dinner, ton...</td>\n",
       "      <td>[trying, out, new, recipe, dinner, tonight]</td>\n",
       "      <td>[tri, out, new, recip, dinner, tonight]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lower_text  \\\n",
       "0   enjoying a beautiful day at the park!        ...   \n",
       "1   traffic was terrible this morning.           ...   \n",
       "2   just finished an amazing workout! ðŸ’ª          ...   \n",
       "3   excited about the upcoming weekend getaway!  ...   \n",
       "4   trying out a new recipe for dinner tonight.  ...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0   enjoying a beautiful day at the park         ...   \n",
       "1   traffic was terrible this morning            ...   \n",
       "2   just finished an amazing workout ðŸ’ª           ...   \n",
       "3   excited about the upcoming weekend getaway   ...   \n",
       "4   trying out a new recipe for dinner tonight   ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0       [enjoying, a, beautiful, day, at, the, park]   \n",
       "1            [traffic, was, terrible, this, morning]   \n",
       "2          [just, finished, an, amazing, workout, ðŸ’ª]   \n",
       "3  [excited, about, the, upcoming, weekend, getaway]   \n",
       "4  [trying, out, a, new, recipe, for, dinner, ton...   \n",
       "\n",
       "                                   no_stopwords  \\\n",
       "0              [enjoying, beautiful, day, park]   \n",
       "1                  [traffic, terrible, morning]   \n",
       "2         [just, finished, amazing, workout, ðŸ’ª]   \n",
       "3  [excited, about, upcoming, weekend, getaway]   \n",
       "4   [trying, out, new, recipe, dinner, tonight]   \n",
       "\n",
       "                            stemmed_tokens  \n",
       "0               [enjoy, beauti, day, park]  \n",
       "1                 [traffic, terribl, morn]  \n",
       "2         [just, finish, amaz, workout, ðŸ’ª]  \n",
       "3  [excit, about, upcom, weekend, getaway]  \n",
       "4  [tri, out, new, recip, dinner, tonight]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Newly added Columns:\\n\")\n",
    "df[[\"lower_text\",\"no_punct\",\"tokens\",\"no_stopwords\",\"stemmed_tokens\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "099930b2-b743-47d5-b89b-c1fa52349a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.75, subjectivity=0.8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Happy</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Happy</td>\n",
       "      <td>(0.6, 0.6000000000000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Happy</td>\n",
       "      <td>(0.3666666666666667, 0.06666666666666667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Happy</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Happy</td>\n",
       "      <td>(0.3, 0.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentiment                                  sentiment\n",
       "727    Happy                                  (0.5, 0.5)\n",
       "728    Happy                   (0.6, 0.6000000000000001)\n",
       "729    Happy   (0.3666666666666667, 0.06666666666666667)\n",
       "730    Happy                                  (0.0, 0.0)\n",
       "731    Happy                                  (0.3, 0.1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(text[0])\n",
    "sentiment = blob.sentiment\n",
    "print(sentiment)\n",
    "\n",
    "sent = []\n",
    "for txt in df[\"stemmed_tokens\"]:\n",
    "    blob = TextBlob(\" \".join(txt))   # join list of tokens into a sentence\n",
    "    sentiment = blob.sentiment\n",
    "    sent.append(sentiment)\n",
    "\n",
    "df[\"sentiment\"] = sent\n",
    "df[[\"Sentiment\",\"sentiment\"]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d362e46-4377-412d-bd3b-cd0c809fffeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
